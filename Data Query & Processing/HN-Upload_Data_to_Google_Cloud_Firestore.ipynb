{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Dataframe to Google Firestore\n",
    "\n",
    "On my recent Hacker News project I ended up building a few nested data views in my pandas dataframe. These views are for plotting the user's comment sentiment over time, and for their top 50 saltiest comments.\n",
    "\n",
    "I needed to find somewhere to host this data for the front end app and after looking over every offering across AWS/Heroku/GoogleCloud I settled on Google Cloud's Cloud Firestore. \n",
    "\n",
    "The price and usability was hard to beat, but the system lacks a simple `csv` upload. And since I had nested values in my dataframe as `str(dict)`s I wanted to un-nest them and take advantage of the document based structure of Google Firestore. \n",
    "\n",
    "This un-nesting string method would work for MongoDB as well. \n",
    "\n",
    "The primary advantage of using Firestore is that I won't have to worry about building a scalable API, and the cost of storage/querying is very low. \n",
    "\n",
    "An added advantage is that my front-end dev partners can write all the code they'd like in JS, and I can write and interact with the database using Python. That's a major win."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Google Cloud Environment\n",
    "\n",
    "I recommend using the [Firestore Quickstart Tutorials](https://cloud.google.com/firestore/docs/quickstart-servers) to get started. You will need to get registered on Google Cloud Platform, and create a Google Cloud Platform project.\n",
    "\n",
    "Follow the instructions to create your database and download the authentication credential (`.json`).\n",
    "\n",
    "Then you will need to set your environment variable as well. If you're using jupyter like me you can put the key in the same folder as your notebook (**ADD THE FILE NAME TO YOUR GITIGNORE**) and then follow the steps below to add the key to your Anaconda env.\n",
    "\n",
    "Via Bash:\n",
    "```\n",
    "cd $CONDA_PREFIX\n",
    "ls\n",
    "mkdir -p ./etc/conda/activate.d\n",
    "mkdir -p ./etc/conda/deactivate.d\n",
    "touch ./etc/conda/activate.d/env_vars.sh\n",
    "touch ./etc/conda/deactivate.d/env_vars.sh\n",
    "nano ./etc/conda/activate.d/env_vars.sh\n",
    "```\n",
    "add these lines: \n",
    "```\n",
    "#!/bin/sh\n",
    "export GOOGLE_APPLICATION_CREDENTIALS=\"yourkey.json\"\n",
    "```\n",
    "then ctrl+x, y.\n",
    "```\n",
    "nano ./etc/conda/deactivate.d/env_vars.s\n",
    "```\n",
    "add these lines:\n",
    "```\n",
    "#!/bin/sh\n",
    "unset GOOGLE_APPLICATION_CREDENTIALS\n",
    "```\n",
    "\n",
    "*Then you're ready to launch your Jupyter notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9563aeeb984045bd1d885d8caa7fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade google-cloud-firestore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "from google.cloud import firestore\n",
    "from tqdm import tqdm_pandas\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# Load TQDM\n",
    "tqdm_pandas(tqdm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Env variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_APPLICATION_CREDENTIALS is set to 'winterrose-nlp-7d9d80973d77.json'\r\n"
     ]
    }
   ],
   "source": [
    "!if [ -z ${GOOGLE_APPLICATION_CREDENTIALS+x} ]; then echo \"GOOGLE_APPLICATION_CREDENTIALS is unset\"; else echo \"GOOGLE_APPLICATION_CREDENTIALS is set to '$GOOGLE_APPLICATION_CREDENTIALS'\";fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Cloud Firestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = firestore.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I created the collection `commentor_stats` manually using the firestore dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ref = db.collection('commentor_stats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few notes about creating new documents on Firestore\n",
    "\n",
    " [The Google Cloud Tutorial for Uploading Data](https://cloud.google.com/firestore/docs/manage-data/add-data)\n",
    "\n",
    "#### Add a document with a specified document id using set  \n",
    "```db.collection(u'cities').document(u'new-city-id').set(data)```\n",
    "\n",
    "#### Let firestore create the id using the .add method. \n",
    "```db.collection(u'cities').add(city.to_dict())```\n",
    "\n",
    "#### The data structure for creating proper imports. \n",
    "```\n",
    "data = {\n",
    "  u'stringExample': u'Hello, World!',\n",
    "  u'booleanExample': True,\n",
    "  u'numberExample': 3.14159265,\n",
    "  u'dateExample': datetime.datetime.now(), #pd.timestamp works too.\n",
    "  u'arrayExample': [5, True, u'hello'],\n",
    "  u'nullExample': None,\n",
    "  u'objectExample': {\n",
    "    u'a': 5,\n",
    "    u'b': True\n",
    "  }\n",
    "```\n",
    "\n",
    "#### Timestamps need to conform to RFC 3339, pd.Timestamp works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now it's time to upload all my data.  First I need to import it to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hn_commentor_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### These are my columns. I'm going to drop a few. \n",
    "[[\"commentor\", # Name of commentor.\n",
    "  \"time_cmnt_lst\", # Most recent comment time in Dataset.\n",
    "  \"time_cmnt_fst\", # First HN comment time.\n",
    "  \"cnt_cmnts_oall\", # Count of total number of comments. \n",
    "  \"sum_slt_oall\", # Total Salt Score Overall. (All Salty + NonSalty Scores added up.)\n",
    "  \"avg_slt_oall\", # Average Comment Salt Score across all comments. \n",
    "  \"cnt_slt_s\", # Count of JUST salty comments. \n",
    "  \"sum_slt_s\", # Total Salt Score of Salty Comments\n",
    "  \"avg_slt_s\", # Average Salt Score of Salty Comments\n",
    "  \"rank_lt_amt_slt\", # Rank: Lifetime Salt Scores Total of Salty comments only.\n",
    "  \"rank_lt_qty_sc\", # Rank: Lifetime quantity of \"Salty Comments\" contributed.\n",
    "  \"rank_oall_slt\", # Rank: Lifetime overall \"Salt Score\" total of All Salty + NonSalty comments. \n",
    "  \"rank_slt_trolls\", # Rank: *ONLY TROLL ACCOUNTS* Lifetime overall \"Salt Score\" total. (Troll accounts are accounts that *ONLY* have salty posts.)\n",
    "  \"top_cmnts_s\", # List of 50 Top Salty Comments. \n",
    "  \"monthly_plot\"]];# List of every month of activity for plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'll make a copy incase something happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 388120 entries, 0 to 388119\n",
      "Data columns (total 15 columns):\n",
      "commentor          388120 non-null object\n",
      "time_cmnt_lst      388120 non-null int64\n",
      "time_cmnt_fst      388120 non-null int64\n",
      "cnt_cmnts_oall     388120 non-null int64\n",
      "sum_slt_oall       388120 non-null float64\n",
      "avg_slt_oall       388120 non-null float64\n",
      "cnt_slt_s          171854 non-null float64\n",
      "sum_slt_s          171854 non-null float64\n",
      "avg_slt_s          171854 non-null float64\n",
      "rank_lt_amt_slt    171854 non-null float64\n",
      "rank_lt_qty_sc     171854 non-null float64\n",
      "rank_oall_slt      818 non-null float64\n",
      "rank_slt_trolls    25055 non-null float64\n",
      "top_cmnts_s        171854 non-null object\n",
      "monthly_plot       388120 non-null object\n",
      "dtypes: float64(9), int64(3), object(3)\n",
      "memory usage: 44.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test = df.copy()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Unix-Epoch times (currently `int`) to Pandas Timestamps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentor</th>\n",
       "      <th>time_cmnt_lst</th>\n",
       "      <th>time_cmnt_fst</th>\n",
       "      <th>cnt_cmnts_oall</th>\n",
       "      <th>sum_slt_oall</th>\n",
       "      <th>avg_slt_oall</th>\n",
       "      <th>cnt_slt_s</th>\n",
       "      <th>sum_slt_s</th>\n",
       "      <th>avg_slt_s</th>\n",
       "      <th>rank_lt_amt_slt</th>\n",
       "      <th>rank_lt_qty_sc</th>\n",
       "      <th>rank_oall_slt</th>\n",
       "      <th>rank_slt_trolls</th>\n",
       "      <th>top_cmnts_s</th>\n",
       "      <th>monthly_plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-</td>\n",
       "      <td>2014-03-14 12:02:05+00:00</td>\n",
       "      <td>2014-03-14 12:02:05+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'y_m': '14_03', 't_s': 0.0, 't_h': 0.12, 'c_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0--__-_-__--0</td>\n",
       "      <td>2018-11-01 19:54:05+00:00</td>\n",
       "      <td>2018-11-01 19:54:05+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.006803</td>\n",
       "      <td>-0.006803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.006803</td>\n",
       "      <td>-0.006803</td>\n",
       "      <td>165340.0</td>\n",
       "      <td>171854.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23113.0</td>\n",
       "      <td>[{'commentor': '0--__-_-__--0', 'comment_time'...</td>\n",
       "      <td>[{'y_m': '18_11', 't_s': -0.01, 't_h': 0.0, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-0</td>\n",
       "      <td>2009-12-03 19:15:12+00:00</td>\n",
       "      <td>2009-12-03 19:15:12+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.280000</td>\n",
       "      <td>-0.280000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.280000</td>\n",
       "      <td>-0.280000</td>\n",
       "      <td>73460.0</td>\n",
       "      <td>147254.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2776.0</td>\n",
       "      <td>[{'commentor': '0-0', 'comment_time': 12598677...</td>\n",
       "      <td>[{'y_m': '09_12', 't_s': -0.28, 't_h': 0.0, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-4</td>\n",
       "      <td>2010-11-01 21:20:10+00:00</td>\n",
       "      <td>2010-10-29 23:19:31+00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>0.753139</td>\n",
       "      <td>0.062762</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.009702</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>162410.0</td>\n",
       "      <td>98565.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'commentor': '0-4', 'comment_time': 12883946...</td>\n",
       "      <td>[{'y_m': '10_10', 't_s': -0.01, 't_h': 0.71, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-9</td>\n",
       "      <td>2018-04-21 15:31:34+00:00</td>\n",
       "      <td>2016-10-28 15:46:02+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'y_m': '16_10', 't_s': 0.0, 't_h': 0.0, 'c_s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       commentor             time_cmnt_lst             time_cmnt_fst  \\\n",
       "0             0- 2014-03-14 12:02:05+00:00 2014-03-14 12:02:05+00:00   \n",
       "1  0--__-_-__--0 2018-11-01 19:54:05+00:00 2018-11-01 19:54:05+00:00   \n",
       "2            0-0 2009-12-03 19:15:12+00:00 2009-12-03 19:15:12+00:00   \n",
       "3            0-4 2010-11-01 21:20:10+00:00 2010-10-29 23:19:31+00:00   \n",
       "4            0-9 2018-04-21 15:31:34+00:00 2016-10-28 15:46:02+00:00   \n",
       "\n",
       "   cnt_cmnts_oall  sum_slt_oall  avg_slt_oall  cnt_slt_s  sum_slt_s  \\\n",
       "0               1      0.120000      0.120000        NaN        NaN   \n",
       "1               1     -0.006803     -0.006803        1.0  -0.006803   \n",
       "2               1     -0.280000     -0.280000        1.0  -0.280000   \n",
       "3              12      0.753139      0.062762        2.0  -0.009702   \n",
       "4               2      0.056250      0.028125        NaN        NaN   \n",
       "\n",
       "   avg_slt_s  rank_lt_amt_slt  rank_lt_qty_sc  rank_oall_slt  rank_slt_trolls  \\\n",
       "0        NaN              NaN             NaN            NaN              NaN   \n",
       "1  -0.006803         165340.0        171854.0            NaN          23113.0   \n",
       "2  -0.280000          73460.0        147254.0            NaN           2776.0   \n",
       "3  -0.004851         162410.0         98565.0            NaN              NaN   \n",
       "4        NaN              NaN             NaN            NaN              NaN   \n",
       "\n",
       "                                         top_cmnts_s  \\\n",
       "0                                                NaN   \n",
       "1  [{'commentor': '0--__-_-__--0', 'comment_time'...   \n",
       "2  [{'commentor': '0-0', 'comment_time': 12598677...   \n",
       "3  [{'commentor': '0-4', 'comment_time': 12883946...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                        monthly_plot  \n",
       "0  [{'y_m': '14_03', 't_s': 0.0, 't_h': 0.12, 'c_...  \n",
       "1  [{'y_m': '18_11', 't_s': -0.01, 't_h': 0.0, 'c...  \n",
       "2  [{'y_m': '09_12', 't_s': -0.28, 't_h': 0.0, 'c...  \n",
       "3  [{'y_m': '10_10', 't_s': -0.01, 't_h': 0.71, '...  \n",
       "4  [{'y_m': '16_10', 't_s': 0.0, 't_h': 0.0, 'c_s...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Unix time to Timestamps\n",
    "test[\"time_cmnt_lst\"] = test[\"time_cmnt_lst\"].apply(lambda x: pd.Timestamp(x, unit='s').tz_localize('UTC'))\n",
    "test[\"time_cmnt_fst\"] = test[\"time_cmnt_fst\"].apply(lambda x: pd.Timestamp(x, unit='s').tz_localize('UTC'))\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 388120 entries, 0 to 388119\n",
      "Data columns (total 15 columns):\n",
      "commentor          388120 non-null object\n",
      "time_cmnt_lst      388120 non-null datetime64[ns, UTC]\n",
      "time_cmnt_fst      388120 non-null datetime64[ns, UTC]\n",
      "cnt_cmnts_oall     388120 non-null int64\n",
      "sum_slt_oall       388120 non-null float64\n",
      "avg_slt_oall       388120 non-null float64\n",
      "cnt_slt_s          171854 non-null float64\n",
      "sum_slt_s          171854 non-null float64\n",
      "avg_slt_s          171854 non-null float64\n",
      "rank_lt_amt_slt    171854 non-null float64\n",
      "rank_lt_qty_sc     171854 non-null float64\n",
      "rank_oall_slt      818 non-null float64\n",
      "rank_slt_trolls    25055 non-null float64\n",
      "top_cmnts_s        171854 non-null object\n",
      "monthly_plot       388120 non-null object\n",
      "dtypes: datetime64[ns, UTC](2), float64(9), int64(1), object(3)\n",
      "memory usage: 44.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I'll use this function to unpack the messy list of comments from `top_cmnts_s' field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\\'commentor\\': \\'0--__-_-__--0\\', \\'comment_time\\': 1541102045, \\'comment_saltiness\\': -0.0068033854, \\'comment_polarity\\': -0.01375, \\'comment_subjectivity\\': 0.4947916667, \\'subjectivity_spectrum\\': 0.0104166667, \\'is_salty\\': True, \\'is_subjective\\': False, \\'is_negative\\': True, \\'parent_type\\': \\'story\\', \\'parent_author\\': \\'macbookaries\\', \\'parent_title\\': \\'People who refuse to drink water, no matter what\\', \\'cleaned_comment\\': \"This doesn\\'t seem that weird. From what I understand it\\'s very rare to drink water in Chinese culture because it was historically necessary to boil it. You drink tea, booze and soup, but not water. If someone with first hand experience can chime in on this I\\'d appreciate it. Same in historical Europe and America - alcoholic beverages were preferred over water for health reasons.\", \\'comment_rank\\': 0.0, \\'comment_id\\': 18357789, \\'parent_id\\': 18356809}]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cmnts = test.iloc[1][\"top_cmnts_s\"]\n",
    "test_cmnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c_0': {'cleaned_comment': \"This doesn't seem that weird. From what I understand it's very rare to drink water in Chinese culture because it was historically necessary to boil it. You drink tea, booze and soup, but not water. If someone with first hand experience can chime in on this I'd appreciate it. Same in historical Europe and America - alcoholic beverages were preferred over water for health reasons.\",\n",
       "  'comment_id': 18357789,\n",
       "  'comment_rank': 0,\n",
       "  'comment_saltiness': -0.0068033854000000005,\n",
       "  'comment_time': Timestamp('2018-11-01 19:54:05+0000', tz='UTC'),\n",
       "  'parent_author': 'macbookaries',\n",
       "  'parent_id': 18356809,\n",
       "  'parent_title': 'People who refuse to drink water, no matter what',\n",
       "  'parent_type': 'story'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dict_top_comments(top_cmnt_obj):\n",
    "    \"\"\"Unpack the top comments and turn it into a good dict.\n",
    "    \n",
    "    Args:\n",
    "        top_cmnt_obj, a str of dicts, from df.top_cmnts_s.\n",
    "    \n",
    "    Evaluates the string, json.dumps it, and reads it back in to a dataframe.\n",
    "    Drops all unecessary columns. \n",
    "    Creates a named index for each comment. \n",
    "    Turns df into an indexed dict. \n",
    "    \n",
    "    Returns: \n",
    "        temp, a properly formed nested dict. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        temp = pd.read_json(json.dumps(eval(top_cmnt_obj)))\n",
    "        temp = temp.drop(columns=[\"subjectivity_spectrum\", \"is_negative\",\n",
    "                                  \"is_salty\", \"is_subjective\", \"comment_polarity\",\n",
    "                                  \"comment_subjectivity\", \"commentor\"]).reset_index()\n",
    "        temp[\"c_id\"] = temp[\"index\"].apply(lambda x: \"c_\" + str(x))\n",
    "        temp[\"comment_time\"] = temp[\"comment_time\"].apply(lambda x: pd.Timestamp(x, unit='s').tz_localize('UTC'))\n",
    "        temp.drop(columns = [\"index\"], inplace = True)\n",
    "        temp = temp.set_index(\"c_id\").to_dict(\"index\")\n",
    "    except:\n",
    "        temp = np.NaN\n",
    "    return temp\n",
    "\n",
    "\n",
    "# Preview the dict after unpacking & cleaning. \n",
    "dict_top_comments(test_cmnts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I'll use this function to unpack / repack my `monthly_plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'y_m': '18_11', 't_s': -0.01, 't_h': 0.0, 'c_s': 1.0, 'c_h': 0.0}]\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_plts = test.iloc[1][\"monthly_plot\"]\n",
    "test_plts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'18_11': {'c_h': 0.0, 'c_s': 1.0, 't_h': 0.0, 't_s': -0.01}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dict_monthly_plot(monthly_plot_obj):\n",
    "    \"\"\"Turns the list of dicts into a nested dict w/ indexes.\n",
    "    \n",
    "    Args:\n",
    "        monthly_plot_obj, an array of dicts.\n",
    "    \n",
    "    Returns: \n",
    "        temp, a dict of dicts. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        temp = pd.DataFrame.from_dict(eval(monthly_plot_obj)).set_index(\"y_m\").to_dict(\"index\")\n",
    "    except:\n",
    "        temp = np.NaN\n",
    "    return temp\n",
    "\n",
    "dict_monthly_plot(test_plts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, I'll use this function to process all the data for upload. \n",
    "This may take a while. :) \n",
    "\n",
    "I'll turn my df into a numpy array of dicts then apply the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = test.iloc[0:].to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install joblib\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a656d76e2f442588e9b635be925d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=379603), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "x_dict = upload\n",
    "def replace_and_upload2(x):\n",
    "    \"\"\"\"\"\"\n",
    "    x[\"monthly_plot\"] = dict_monthly_plot(x[\"monthly_plot\"])\n",
    "    x[\"top_cmnts_s\"] = dict_top_comments(x[\"top_cmnts_s\"])\n",
    "    print(\"uploaded \", x[\"commentor\"])\n",
    "    return x\n",
    "results =[]\n",
    "results.append(Parallel(n_jobs=7)(delayed(replace_and_upload2)(x) for x in tqdm(x_dict)))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I had to restart this a few times due to random errors. Added error handling and fixed it, but this is where my process had to begin again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'commentor': 'searchencrypt', 'time_cmnt_lst': Timestamp('2018-10-24 20:31:28+0000', tz='UTC'), 'time_cmnt_fst': Timestamp('2018-01-03 14:49:33+0000', tz='UTC'), 'cnt_cmnts_oall': 19, 'sum_slt_oall': 1.1310191256191158, 'avg_slt_oall': 0.05952732240100609, 'cnt_slt_s': 2.0, 'sum_slt_s': -0.5180357142857143, 'avg_slt_s': -0.25901785714285713, 'rank_lt_amt_slt': 55279.0, 'rank_lt_qty_sc': 79543.0, 'rank_oall_slt': nan, 'rank_slt_trolls': nan, 'top_cmnts_s': {'c_0': {'cleaned_comment': 'Bezos says, “If you make customers unhappy in the physical world, they might each tell six friends. If you make customers unhappy on the Internet, they can each tell 6,000.” Tracking people makes them :(', 'comment_id': 16643222, 'comment_rank': 0, 'comment_saltiness': -0.3586607143, 'comment_time': Timestamp('2018-03-21 22:56:33+0000', tz='UTC'), 'parent_author': 'dwyerm', 'parent_id': 16642584, 'parent_title': 'Another Comment', 'parent_type': 'comment'}, 'c_1': {'cleaned_comment': \"It's news because people use VPNs to protect their privacy. If they are under the impression that Onavo will keep their data private, they are wrong. Just trying to inform...\", 'comment_id': 16530892, 'comment_rank': 0, 'comment_saltiness': -0.159375, 'comment_time': Timestamp('2018-03-06 18:38:59+0000', tz='UTC'), 'parent_author': 'djrogers', 'parent_id': 16530871, 'parent_title': 'Another Comment', 'parent_type': 'comment'}}, 'monthly_plot': {'18_01': {'c_h': 3.0, 'c_s': 0.0, 't_h': 0.38, 't_s': 0.0}, '18_02': {'c_h': 2.0, 'c_s': 0.0, 't_h': 0.73, 't_s': 0.0}, '18_03': {'c_h': 8.0, 'c_s': 2.0, 't_h': 0.42, 't_s': -0.52}, '18_04': {'c_h': 3.0, 'c_s': 0.0, 't_h': 0.12, 't_s': 0.0}, '18_10': {'c_h': 1.0, 'c_s': 0.0, 't_h': 0.0, 't_s': 0.0}}}, {'commentor': 'searchengineguy', 'time_cmnt_lst': Timestamp('2016-12-13 19:52:33+0000', tz='UTC'), 'time_cmnt_fst': Timestamp('2016-12-13 19:52:33+0000', tz='UTC'), 'cnt_cmnts_oall': 1, 'sum_slt_oall': 0.1875, 'avg_slt_oall': 0.1875, 'cnt_slt_s': nan, 'sum_slt_s': nan, 'avg_slt_s': nan, 'rank_lt_amt_slt': nan, 'rank_lt_qty_sc': nan, 'rank_oall_slt': nan, 'rank_slt_trolls': nan, 'top_cmnts_s': nan, 'monthly_plot': {'16_12': {'c_h': 1.0, 'c_s': 0.0, 't_h': 0.19, 't_s': 0.0}}}]\n"
     ]
    }
   ],
   "source": [
    "print(results[0][304849:304851])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{'commentor': 'zzzzzzzzzzz', 'time_cmnt_lst': Timestamp('2018-10-13 14:18:32+0000', tz='UTC'), 'time_cmnt_fst': Timestamp('2018-10-13 14:18:32+0000', tz='UTC'), 'cnt_cmnts_oall': 1, 'sum_slt_oall': 0.0, 'avg_slt_oall': 0.0, 'cnt_slt_s': nan, 'sum_slt_s': nan, 'avg_slt_s': nan, 'rank_lt_amt_slt': nan, 'rank_lt_qty_sc': nan, 'rank_oall_slt': nan, 'rank_slt_trolls': nan, 'top_cmnts_s': nan, 'monthly_plot': {'18_10': {'c_h': 1.0, 'c_s': 0.0, 't_h': 0.0, 't_s': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "final = results[0][-:]\n",
    "print(len(final))\n",
    "print(final[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And here's the upload function. \n",
    "\n",
    "Notice how it batches the records into groups of 500 then submits them. The submission step was having the occasional timeout but adding the `try` worked great. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2063148b7a854b96bf6cc5007150cba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=74753), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set batch\n",
      "sent batch 1\n",
      "sent batch 2\n",
      "sent batch 3\n",
      "sent batch 4\n",
      "sent batch 5\n",
      "sent batch 6\n",
      "sent batch 7\n",
      "sent batch 8\n",
      "sent batch 9\n",
      "sent batch 10\n",
      "sent batch 11\n",
      "sent batch 12\n",
      "sent batch 13\n",
      "sent batch 14\n",
      "sent batch 15\n",
      "sent batch 16\n",
      "sent batch 17\n",
      "sent batch 18\n",
      "sent batch 19\n",
      "sent batch 20\n",
      "sent batch 21\n",
      "sent batch 22\n",
      "sent batch 23\n",
      "sent batch 24\n",
      "sent batch 25\n",
      "sent batch 26\n",
      "sent batch 27\n",
      "sent batch 28\n",
      "sent batch 29\n",
      "sent batch 30\n",
      "sent batch 31\n",
      "sent batch 32\n",
      "sent batch 33\n",
      "sent batch 34\n",
      "sent batch 35\n",
      "sent batch 36\n",
      "sent batch 37\n",
      "sent batch 38\n",
      "sent batch 39\n",
      "sent batch 40\n",
      "sent batch 41\n",
      "sent batch 42\n",
      "sent batch 43\n",
      "sent batch 44\n",
      "sent batch 45\n",
      "sent batch 46\n",
      "sent batch 47\n",
      "sent batch 48\n",
      "sent batch 49\n",
      "sent batch 50\n",
      "sent batch 51\n",
      "sent batch 52\n",
      "sent batch 53\n",
      "sent batch 54\n",
      "sent batch 55\n",
      "sent batch 56\n",
      "sent batch 57\n",
      "sent batch 58\n",
      "sent batch 59\n",
      "sent batch 60\n",
      "sent batch 61\n",
      "sent batch 62\n",
      "sent batch 63\n",
      "sent batch 64\n",
      "sent batch 65\n",
      "sent batch 66\n",
      "sent batch 67\n",
      "sent batch 68\n",
      "sent batch 69\n",
      "sent batch 70\n",
      "sent batch 71\n",
      "sent batch 72\n",
      "sent batch 73\n",
      "sent batch 74\n",
      "sent batch 75\n",
      "sent batch 76\n",
      "sent batch 77\n",
      "sent batch 78\n",
      "sent batch 79\n",
      "sent batch 80\n",
      "sent batch 81\n",
      "sent batch 82\n",
      "sent batch 83\n",
      "sent batch 84\n",
      "sent batch 85\n",
      "sent batch 86\n",
      "sent batch 87\n",
      "sent batch 88\n",
      "sent batch 89\n",
      "sent batch 90\n",
      "sent batch 91\n",
      "sent batch 92\n",
      "sent batch 93\n",
      "sent batch 94\n",
      "sent batch 95\n",
      "sent batch 96\n",
      "sent batch 97\n",
      "sent batch 98\n",
      "Commit of batch 99 failed... reattempting.\n",
      "sent batch 99\n",
      "sent batch 100\n",
      "sent batch 101\n",
      "sent batch 102\n",
      "sent batch 103\n",
      "sent batch 104\n",
      "sent batch 105\n",
      "sent batch 106\n",
      "sent batch 107\n",
      "sent batch 108\n",
      "sent batch 109\n",
      "sent batch 110\n",
      "sent batch 111\n",
      "sent batch 112\n",
      "sent batch 113\n",
      "sent batch 114\n",
      "sent batch 115\n",
      "sent batch 116\n",
      "sent batch 117\n",
      "sent batch 118\n",
      "sent batch 119\n",
      "sent batch 120\n",
      "sent batch 121\n",
      "sent batch 122\n",
      "sent batch 123\n",
      "sent batch 124\n",
      "sent batch 125\n",
      "sent batch 126\n",
      "sent batch 127\n",
      "sent batch 128\n",
      "sent batch 129\n",
      "sent batch 130\n",
      "sent batch 131\n",
      "sent batch 132\n",
      "sent batch 133\n",
      "sent batch 134\n",
      "sent batch 135\n",
      "sent batch 136\n",
      "sent batch 137\n",
      "sent batch 138\n",
      "sent batch 139\n",
      "sent batch 140\n",
      "sent batch 141\n",
      "sent batch 142\n",
      "sent batch 143\n",
      "sent batch 144\n",
      "sent batch 145\n",
      "sent batch 146\n",
      "sent batch 147\n",
      "sent batch 148\n",
      "sent batch 149\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "x = 1\n",
    "batch_no = 1\n",
    "for entry in tqdm(final):\n",
    "    if x == 1:\n",
    "        # Do this part the first time.\n",
    "        batch = db.batch()\n",
    "        print(\"set batch\")\n",
    "        \n",
    "    # Do this part for every single one. \n",
    "    #print (\"added %s to batch\" % x)\n",
    "    batch.set(db.collection(u'commentor_stats').document(), entry)\n",
    "    \n",
    "    if x % 500 == 0:\n",
    "        #Do this part every 500th time.\n",
    "        #Had to add a try/except for this pesky submission error.\n",
    "        try:\n",
    "            batch.commit()\n",
    "        except:\n",
    "            print(\"Commit of batch %s failed... reattempting.\" % batch_no)\n",
    "            sleep(5) # Wait 5 seconds, then retry. \n",
    "            batch.commit()\n",
    "        print(\"sent batch %s\" % batch_no)\n",
    "        batch = db.batch()\n",
    "        batch_no += 1\n",
    "    x += 1\n",
    "\n",
    "# One last batch commit to send the last non-500 docsize batch.\n",
    "batch.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basic outline for batch uploading. \n",
    "#batch = db.batch()\n",
    "#batch.set(db.collection(u'commentor_stats').document(),{u'commentor': u'ZTESTZZZZZ'})\n",
    "#batch.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
